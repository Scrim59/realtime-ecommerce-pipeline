ğŸ“Š Real-Time Ecommerce Pipeline

Kafka â€¢ Spark Structured Streaming â€¢ PostgreSQL â€¢ Metabase

Real-time data engineering project processing e-commerce orders end-to-end:
data generation â†’ Kafka â†’ Spark streaming transformations â†’ PostgreSQL â†’ analytics dashboard in Metabase.

â¸»

ğŸš€ Architecture Overview
```text
+------------------+        +-----------------+        +------------------+
|  Generator (Py)  |  -->   |     Kafka       |  -->   |   Spark Streaming|
+------------------+        +-----------------+        +------------------+
                                                             |
                                                             v
                                                    +------------------+
                                                    |   PostgreSQL     |
                                                    +------------------+
                                                             |
                                                             v
                                                    +------------------+
                                                    |    Metabase      |
                                                    +------------------+
```

â¸»

ğŸ§° Tech Stack
	â€¢	Python (order generator, Kafka producer)
	â€¢	Apache Kafka
	â€¢	Spark Structured Streaming
	â€¢	PostgreSQL
	â€¢	Metabase
	â€¢	Docker Compose

â¸»

ğŸ“¦ Project Structure

```text 
realtime-ecommerce-pipeline/
â”‚
â”œâ”€â”€ generator/          # Kafka producer generating fake orders
â”œâ”€â”€ spark/              # Spark Structured Streaming job
â”œâ”€â”€ database/           # PostgreSQL init sql, docker config
â”œâ”€â”€ dashboard/          # Metabase docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ ...

```


â¸»

ğŸ”§ How to Run Locally

1ï¸âƒ£ Start Kafka, Zookeeper, and PostgreSQL

``bash
docker compose -f docker-compose.yml up -d
```
2ï¸âƒ£ Start the order generator

```bash
cd generator
python generate_orders.py
```
3ï¸âƒ£ Start Spark streaming job

```bash
cd spark
python stream_orders.py
```

4ï¸âƒ£ Run Metabase

```bash
cd dashboard
docker compose up -d
```
Access Metabase at:
http://localhost:3000


â¸»
ğŸ“ˆ Dashboard (Screenshots)

Metabase runs locally in one command, but screenshots are provided.

![dashboard](dashboard/dashboard.png)

â¸»
ğŸ”¥ Features

âœ” Real-time ingestion using Kafka
âœ” Nested JSON schema (customer + items)
âœ” Flattening & exploding arrays in Spark
âœ” Writing to PostgreSQL with UPSERT logic
âœ” Real-time analytics dashboard in Metabase
âœ” Fully reproducible setup with Docker

â¸»

ğŸ“¬ Notes.

This project demonstrates:
	â€¢	Real-time streaming architecture
	â€¢	Handling nested JSON data
	â€¢	OLTP â†’ OLAP pipeline
	â€¢	Dashboard creation
	â€¢	Production-style Spark & SQL logic
	â€¢	Deduplication and UPSERT handling

Everything runs locally in ~3 minutes.

â¸»

ğŸ‘¤ Author

MichaÅ‚ Lipa
